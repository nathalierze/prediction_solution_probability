{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "path = '#'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import preprocessed data\n",
    "infile = open('final_data_preprocessed.pkl','rb')\n",
    "import_file = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "# balance out dataset\n",
    "df1 = import_file[import_file['Erfolg'] == 0]\n",
    "df2 = import_file[import_file['Erfolg'] == 1]\n",
    "df1 = df1.sample(n=100000)\n",
    "df2 = df2.sample(n=100000)\n",
    "\n",
    "# append balanced dataset\n",
    "import_file_small = df1.append(df2)\n",
    "import_file_small.to_pickle('balanced_dataset_small_3months.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## only keep neccessary features\n",
    "smaller_features=import_file_small[['UserID','Erstloesung','Erfolg','Schwierigkeit','Wochentag','ist_Schulzeit','MehrfachFalsch','Testposition__FT', 'Testposition__nt', 'Testposition__pruefung',\n",
    "       'Testposition__training', 'Testposition__version', 'Testposition__vt',\n",
    "       'Testposition__zt', 'beendet', 'Fehler', 'HA__HA', 'HA__Self', 'HA__nt',\n",
    "       'HA__vt', 'HA__zt', 'Klassenstufe', 'Jahredabei',\n",
    "       'Sex__m', 'Sex__w']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all sentences\n",
    "infile = open(path+'saetze.pkl','rb')\n",
    "saetze = pickle.load(infile)\n",
    "infile.close()\n",
    "saetze = saetze[['satzID','Schwierigkeit','Art','AufgabenID']]\n",
    "\n",
    "#Art: only GK\n",
    "options = ['GK'] \n",
    "saetze = saetze[saetze['Art'].isin(options)] \n",
    "\n",
    "#Aufgaben ID : all except 0 (0 is kompetenztests) \n",
    "options = ['0'] \n",
    "saetze = saetze[~saetze['AufgabenID'].isin(options)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create empty df with null values\n",
    "# rows: all userIDs from preprocessed and balanced dataset\n",
    "# columns: all satzIDs\n",
    "userIDs = import_file_small[['UserID']]\n",
    "userIDs = userIDs.drop_duplicates()\n",
    "index_col = userIDs['UserID'].tolist()\n",
    "satzList = saetze[\"satzID\"].tolist()\n",
    "df = pd.DataFrame(0, index =index_col,columns =satzList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import xmlsaetze and xmlsaetze archiv\n",
    "\n",
    "infile = open(path+'xmlsaetze.pkl','rb')\n",
    "xmlsaetze = pickle.load(infile)\n",
    "infile.close()\n",
    "xmlsaetze = xmlsaetze[['ID','UserID','UebungsID','SatzID','Erfolg','Datum']]\n",
    "\n",
    "infile = open(path+'xmlsaetze_archiv.pkl','rb')\n",
    "xmlsaetze_archiv = pickle.load(infile)\n",
    "infile.close()\n",
    "xmlsaetze_archiv = xmlsaetze_archiv[['ID','UserID','UebungsID','SatzID','Erfolg','Datum']]\n",
    "\n",
    "xmlsaetze = xmlsaetze.append(xmlsaetze_archiv)\n",
    "xmlsaetze_small = xmlsaetze[['UserID','SatzID','Erfolg','Datum']]\n",
    "\n",
    "# filter satzID: only GK and not kompetenztests\n",
    "options = saetze['satzID'].tolist()\n",
    "xmlsaetze_small = xmlsaetze_small[xmlsaetze_small['SatzID'].isin(options)] \n",
    "\n",
    "# filter unserID: only User which appear in preprocessed dataset\n",
    "options = index_col\n",
    "xmlsaetze_userid = xmlsaetze_small[xmlsaetze_small['UserID'].isin(options)] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add column last_login\n",
    "# not neccessary in production: in production we use t-3months \n",
    "# neccessary for training\n",
    "last_login = xmlsaetze_userid[['UserID','Datum']].groupby(['UserID']).max()\n",
    "last_login = pd.DataFrame(last_login.reset_index())\n",
    "last_login = last_login.rename(columns={\"Datum\": \"last_login\"})\n",
    "\n",
    "# merge last login \n",
    "xmlsaetze_userid_last_login= xmlsaetze_userid.merge(last_login, on='UserID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## iterate through xmlsaetze to finde historical data for each user\n",
    "\n",
    "for i in range(xmlsaetze_userid_last_login.shape[0]): #iterate trough dataframe row-wise\n",
    "    user_cell = xmlsaetze_userid_last_login.iloc[i,0]\n",
    "    satz_cell = xmlsaetze_userid_last_login.iloc[i,1]\n",
    "    erfolg_cell = xmlsaetze_userid_last_login.iloc[i,2]\n",
    "    datum_cell = xmlsaetze_userid_last_login.iloc[i,3]\n",
    "    last_login_cell = xmlsaetze_userid_last_login.iloc[i,4]\n",
    "\n",
    "    dateOfExercise = datetime.strptime(str(datum_cell), '%Y-%m-%d %H:%M:%S').date()\n",
    "    dateOfLastLogin = datetime.strptime(str(last_login_cell), '%Y-%m-%d %H:%M:%S').date()\n",
    "    acceptedDate = dateOfLastLogin + pd.DateOffset(months=-3) # accepted date calculates the date of the last login minus 3 months\n",
    "\n",
    "    #check if sentence and user is in df\n",
    "    if satz_cell in df.columns:\n",
    "        if user_cell in df.index:\n",
    "            if(dateOfExercise > acceptedDate):\n",
    "                # set new cell value\n",
    "                if(erfolg_cell == 1):\n",
    "                    df.loc[user_cell,satz_cell] = 1\n",
    "                elif (erfolg_cell ==0):\n",
    "                    df.loc[user_cell,satz_cell] = -1          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge, and save\n",
    "historical_join = df.reset_index()\n",
    "historical_join = historical_join.rename(columns={\"index\": \"UserID\"})\n",
    "historical_join.to_pickle('historicalJoin_3months.pkl')\n",
    "\n",
    "df = pd.merge(smaller_features, historical_join, how='left', on='UserID')\n",
    "df.to_pickle('smallSampleSet_3months.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates\n",
    "df = df.drop(columns=['UserID'])\n",
    "df = df.drop_duplicates(keep='first')\n",
    "\n",
    "# save as pickle\n",
    "df.to_pickle('FINALsmallSampleSet_3months_without_duplicates.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
