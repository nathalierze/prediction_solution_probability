{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold , cross_val_score\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import mean, absolute\n",
    "import openpyxl\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot\n",
    "from tensorflow.keras.models import load_model\n",
    "import warnings\n",
    "\n",
    "# Ignore the warning message\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from sklearn.metrics import log_loss, confusion_matrix, roc_auc_score, recall_score, precision_score, average_precision_score, f1_score, classification_report, accuracy_score, plot_roc_curve, plot_precision_recall_curve, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import feature list\n",
    "infile = open('../01_solution_probability_model/data_solution_probability_model.pkl','rb')\n",
    "import_file = pickle.load(infile)\n",
    "infile.close()\n",
    "df = import_file\n",
    "feature_cols = list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(clf,X_train,y_train,X_test,y_test,cv):\n",
    "    \"\"\"\n",
    "    function to predict y and to calculate all scores neccessary for fairness evaluation\n",
    "    \"\"\"\n",
    "    scores_a = cross_val_score(clf, X_train,y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    accuracy = mean(absolute(scores_a))\n",
    "    scores_p = cross_val_score(clf,X_train,y_train, scoring='precision', cv=cv, n_jobs=-1)\n",
    "    precision = mean(absolute(scores_p))\n",
    "    scores_r = cross_val_score(clf, X_train,y_train, scoring='recall', cv=cv, n_jobs=-1)\n",
    "    recall = mean(absolute(scores_r))\n",
    "    scores_auc = cross_val_score(clf, X_train,y_train, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "    roc_auc_cv = mean(absolute(scores_auc))\n",
    "\n",
    "    pred = clf.predict(X_test)\n",
    "    a = accuracy_score(y_test,pred)\n",
    "    p = precision_score(y_test,pred)\n",
    "    r = recall_score(y_test,pred)\n",
    "    roc_auc = roc_auc_score(y_test,pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "    fpr = fp/(fp+tn)\n",
    "\n",
    "    return a,p,r,roc_auc,fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## list subgroups\n",
    "fair_metrics = pd.DataFrame(columns=['model', 'group', 'subgroup', 'Accuracy', 'Precision', 'Recall', 'AUC', 'FPR'])\n",
    "matrice = ['double_df_abi','double_df_keinAbi','double_df_boys','double_df_girls','double_df_deutsch','double_df_migration','double_df_buch0','double_df_buch1']\n",
    "group = ['abiEltern', 'abiEltern', 'gender', 'gender', 'erstsprache', 'erstsprache', 'buecher', 'buecher']\n",
    "subgroup = ['abi', 'keinAbi', 'boys', 'girls', 'deutsch', 'migration', 'buch0', 'buch1']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "DTE_model = pickle.load(open('../01_solution_probability_model/01_decision_tree/Decisiontreemodel_3months.pkl', 'rb'))\n",
    "\n",
    "# predict for each subgroup\n",
    "for (group, subgroup, matrice) in zip(group, subgroup, matrice):\n",
    "    print(matrice)\n",
    "    path= 'matrices_subgroups/'+matrice+'.pkl'\n",
    "    infile = open(path,'rb')\n",
    "    df = pickle.load(infile)\n",
    "    infile.close()\n",
    "\n",
    "    dataset= df[df.columns[df.columns.isin(feature_cols)]]\n",
    "    y = dataset['Erfolg']\n",
    "    X = dataset.drop(columns=['Erfolg'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=1\n",
    "    )\n",
    "    k = 5\n",
    "    cv = KFold(n_splits=k, random_state=None)\n",
    "    a,p,r,roc_auc,fpr = get_metrics(DTE_model,X_train,y_train,X_test,y_test,cv)\n",
    "    fair_metrics = fair_metrics.append({'model':'DTE','group':group,'subgroup':subgroup,'Accuracy':a,'Precision': p, 'Recall':r, 'AUC':roc_auc, 'FPR':fpr}, ignore_index=True)\n",
    "\n",
    "fair_metrics.to_excel('metrics/dte_metrics.xlsx')\n",
    "fair_metrics.to_pickle('metrics/dte_metrics.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "logreg_model = pickle.load(open('../01_solution_probability_model/02_logistic_regression/Logregmodel_3months.pkl', 'rb'))\n",
    "\n",
    "# predict for each subgroup\n",
    "for (group, subgroup, matrice) in zip(group, subgroup, matrice):\n",
    "    path= matrice+'.pkl'\n",
    "    infile = open(path,'rb')\n",
    "    df = pickle.load(infile)\n",
    "    infile.close()\n",
    "\n",
    "    dataset = df[df.columns[df.columns.isin(feature_cols)]]\n",
    "    y = dataset['Erfolg']\n",
    "    X = dataset.drop(columns=['Erfolg'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=1\n",
    "    )\n",
    "    k = 5\n",
    "    cv = KFold(n_splits=k, random_state=None)\n",
    "    a,p,r,roc_auc,fpr = get_metrics(logreg_model,X_train,y_train,X_test,y_test,cv)\n",
    "    fair_metrics = fair_metrics.append({'model':'LogReg','group':group,'subgroup':subgroup,'Accuracy':a,'Precision': p, 'Recall':r, 'AUC':roc_auc, 'FPR':fpr}, ignore_index=True)\n",
    "\n",
    "fair_metrics.to_excel('metrics/log_metrics.xlsx')\n",
    "fair_metrics.to_pickle('metrics/log_metrics.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "svm_model = pickle.load(open('../01_solution_probability_model/03_svm/SVMmodel_3months.pkl', 'rb'))\n",
    "\n",
    "# predict for each subgroup\n",
    "for (group, subgroup, matrice) in zip(group, subgroup, matrice):\n",
    "    path= matrice+'.pkl'\n",
    "    infile = open(path,'rb')\n",
    "    df = pickle.load(infile)\n",
    "    infile.close()\n",
    "\n",
    "    dataset = df[df.columns[df.columns.isin(feature_cols)]]\n",
    "    y = dataset['Erfolg']\n",
    "    X = dataset.drop(columns=['Erfolg'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=1\n",
    "    )\n",
    "    k = 5\n",
    "    cv = KFold(n_splits=k, random_state=None)\n",
    "    a,p,r,roc_auc,fpr = get_metrics(svm_model,X_train,y_train,X_test,y_test,cv)\n",
    "    fair_metrics = fair_metrics.append({'model':'SVM','group':group,'subgroup':subgroup,'Accuracy':a,'Precision': p, 'Recall':r, 'AUC':roc_auc, 'FPR':fpr}, ignore_index=True)\n",
    "\n",
    "fair_metrics.to_excel('metrics/svm_metrics.xlsx')\n",
    "fair_metrics.to_pickle('metrics/svm_metrics.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dn_metrics(model,X_test,y_test):\n",
    "    \"\"\"\n",
    "    function to predict y in nn model\n",
    "    return all metrics neccessary for fairness evaluation\n",
    "    \"\"\"\n",
    "    X_test = np.asarray(X_test).astype('float32')\n",
    "    yhat_probs = model.predict(X_test, verbose=0)\n",
    "    yhat_classes =  (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "    # reduce to 1d array\n",
    "    yhat_probs = yhat_probs[:, 0]\n",
    "    yhat_classes = yhat_classes[:, 0]\n",
    "    a = accuracy_score(y_test, yhat_classes)\n",
    "    p = precision_score(y_test, yhat_classes)\n",
    "    r = recall_score(y_test, yhat_classes)\n",
    "    roc_auc = roc_auc_score(y_test, yhat_probs)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, yhat_classes).ravel()\n",
    "    fpr = fp/(fp+tn)\n",
    "\n",
    "    return a,p,r,roc_auc,fpr\n",
    "\n",
    "# load model\n",
    "nn_model = load_model('../01_solution_probability_model/04_nn/nn/')\n",
    "\n",
    "# predict for each subgroup\n",
    "for (group, subgroup, matrice) in zip(group, subgroup, matrice):\n",
    "    path= matrice+'.pkl'\n",
    "    infile = open(path,'rb')\n",
    "    df = pickle.load(infile)\n",
    "    infile.close()\n",
    "\n",
    "    dataset = df[df.columns[df.columns.isin(feature_cols)]]\n",
    "    y = dataset['Erfolg']\n",
    "    X = dataset.drop(columns=['Erfolg'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=1\n",
    "    )\n",
    "    a,p,r,roc_auc,fpr = get_dn_metrics(nn_model,X_test,y_test)\n",
    "    fair_metrics = fair_metrics.append({'model':'NN','group':group,'subgroup':subgroup,'Accuracy':a,'Precision': p, 'Recall':r, 'AUC':roc_auc, 'FPR':fpr}, ignore_index=True)\n",
    "\n",
    "fair_metrics.to_excel('metrics/nn_metrics.xlsx')\n",
    "fair_metrics.to_pickle('metrics/nn_metrics.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
