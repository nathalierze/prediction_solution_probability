{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import mean, absolute\n",
    "import openpyxl\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot\n",
    "from tensorflow.keras.models import load_model\n",
    "import warnings\n",
    "\n",
    "# Ignore the warning message\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from sklearn.metrics import (\n",
    "    log_loss,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    average_precision_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    accuracy_score,\n",
    "    plot_roc_curve,\n",
    "    plot_precision_recall_curve,\n",
    "    plot_confusion_matrix,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import feature list\n",
    "infile = open(\n",
    "    \"../01_solution_probability_model/data_solution_probability_model.pkl\", \"rb\"\n",
    ")\n",
    "import_file = pickle.load(infile)\n",
    "infile.close()\n",
    "df = import_file\n",
    "feature_cols = list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(clf, X_train, y_train, X_test, y_test, cv):\n",
    "    \"\"\"\n",
    "    function to predict y and to calculate all scores neccessary for fairness evaluation\n",
    "    \"\"\"\n",
    "    scores_a = cross_val_score(\n",
    "        clf, X_train, y_train, scoring=\"accuracy\", cv=cv, n_jobs=-1\n",
    "    )\n",
    "    accuracy = mean(absolute(scores_a))\n",
    "    scores_p = cross_val_score(\n",
    "        clf, X_train, y_train, scoring=\"precision\", cv=cv, n_jobs=-1\n",
    "    )\n",
    "    precision = mean(absolute(scores_p))\n",
    "    scores_r = cross_val_score(\n",
    "        clf, X_train, y_train, scoring=\"recall\", cv=cv, n_jobs=-1\n",
    "    )\n",
    "    recall = mean(absolute(scores_r))\n",
    "    scores_auc = cross_val_score(\n",
    "        clf, X_train, y_train, scoring=\"roc_auc\", cv=cv, n_jobs=-1\n",
    "    )\n",
    "    roc_auc_cv = mean(absolute(scores_auc))\n",
    "\n",
    "    pred = clf.predict(X_test)\n",
    "    a = accuracy_score(y_test, pred)\n",
    "    p = precision_score(y_test, pred)\n",
    "    r = recall_score(y_test, pred)\n",
    "    roc_auc = roc_auc_score(y_test, pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "    fpr = fp / (fp + tn)\n",
    "\n",
    "    return a, p, r, roc_auc, fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## list subgroups\n",
    "fair_metrics = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"model\",\n",
    "        \"group\",\n",
    "        \"subgroup\",\n",
    "        \"Accuracy\",\n",
    "        \"Precision\",\n",
    "        \"Recall\",\n",
    "        \"AUC\",\n",
    "        \"FPR\",\n",
    "    ]\n",
    ")\n",
    "matrice = [\n",
    "    \"double_df_abi\",\n",
    "    \"double_df_keinAbi\",\n",
    "    \"double_df_boys\",\n",
    "    \"double_df_girls\",\n",
    "    \"double_df_deutsch\",\n",
    "    \"double_df_migration\",\n",
    "    \"double_df_buch0\",\n",
    "    \"double_df_buch1\",\n",
    "]\n",
    "group = [\n",
    "    \"abiEltern\",\n",
    "    \"abiEltern\",\n",
    "    \"gender\",\n",
    "    \"gender\",\n",
    "    \"erstsprache\",\n",
    "    \"erstsprache\",\n",
    "    \"buecher\",\n",
    "    \"buecher\",\n",
    "]\n",
    "subgroup = [\"abi\", \"keinAbi\", \"boys\", \"girls\", \"deutsch\", \"migration\", \"buch0\", \"buch1\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "DTE_model = pickle.load(\n",
    "    open(\n",
    "        \"../01_solution_probability_model/01_decision_tree/Decisiontreemodel_3months.pkl\",\n",
    "        \"rb\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# predict for each subgroup\n",
    "for group, subgroup, matrice in zip(group, subgroup, matrice):\n",
    "    print(matrice)\n",
    "    path = \"matrices_subgroups/\" + matrice + \".pkl\"\n",
    "    infile = open(path, \"rb\")\n",
    "    df = pickle.load(infile)\n",
    "    infile.close()\n",
    "\n",
    "    dataset = df[df.columns[df.columns.isin(feature_cols)]]\n",
    "    y = dataset[\"Erfolg\"]\n",
    "    X = dataset.drop(columns=[\"Erfolg\"])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=1\n",
    "    )\n",
    "    k = 5\n",
    "    cv = KFold(n_splits=k, random_state=None)\n",
    "    a, p, r, roc_auc, fpr = get_metrics(DTE_model, X_train, y_train, X_test, y_test, cv)\n",
    "    fair_metrics = fair_metrics.append(\n",
    "        {\n",
    "            \"model\": \"DTE\",\n",
    "            \"group\": group,\n",
    "            \"subgroup\": subgroup,\n",
    "            \"Accuracy\": a,\n",
    "            \"Precision\": p,\n",
    "            \"Recall\": r,\n",
    "            \"AUC\": roc_auc,\n",
    "            \"FPR\": fpr,\n",
    "        },\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "fair_metrics.to_excel(\"metrics/dte_metrics.xlsx\")\n",
    "fair_metrics.to_pickle(\"metrics/dte_metrics.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "logreg_model = pickle.load(\n",
    "    open(\n",
    "        \"../01_solution_probability_model/02_logistic_regression/Logregmodel_3months.pkl\",\n",
    "        \"rb\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# predict for each subgroup\n",
    "for group, subgroup, matrice in zip(group, subgroup, matrice):\n",
    "    path = matrice + \".pkl\"\n",
    "    infile = open(path, \"rb\")\n",
    "    df = pickle.load(infile)\n",
    "    infile.close()\n",
    "\n",
    "    dataset = df[df.columns[df.columns.isin(feature_cols)]]\n",
    "    y = dataset[\"Erfolg\"]\n",
    "    X = dataset.drop(columns=[\"Erfolg\"])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=1\n",
    "    )\n",
    "    k = 5\n",
    "    cv = KFold(n_splits=k, random_state=None)\n",
    "    a, p, r, roc_auc, fpr = get_metrics(\n",
    "        logreg_model, X_train, y_train, X_test, y_test, cv\n",
    "    )\n",
    "    fair_metrics = fair_metrics.append(\n",
    "        {\n",
    "            \"model\": \"LogReg\",\n",
    "            \"group\": group,\n",
    "            \"subgroup\": subgroup,\n",
    "            \"Accuracy\": a,\n",
    "            \"Precision\": p,\n",
    "            \"Recall\": r,\n",
    "            \"AUC\": roc_auc,\n",
    "            \"FPR\": fpr,\n",
    "        },\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "fair_metrics.to_excel(\"metrics/log_metrics.xlsx\")\n",
    "fair_metrics.to_pickle(\"metrics/log_metrics.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "svm_model = pickle.load(\n",
    "    open(\"../01_solution_probability_model/03_svm/SVMmodel_3months.pkl\", \"rb\")\n",
    ")\n",
    "\n",
    "# predict for each subgroup\n",
    "for group, subgroup, matrice in zip(group, subgroup, matrice):\n",
    "    path = matrice + \".pkl\"\n",
    "    infile = open(path, \"rb\")\n",
    "    df = pickle.load(infile)\n",
    "    infile.close()\n",
    "\n",
    "    dataset = df[df.columns[df.columns.isin(feature_cols)]]\n",
    "    y = dataset[\"Erfolg\"]\n",
    "    X = dataset.drop(columns=[\"Erfolg\"])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=1\n",
    "    )\n",
    "    k = 5\n",
    "    cv = KFold(n_splits=k, random_state=None)\n",
    "    a, p, r, roc_auc, fpr = get_metrics(svm_model, X_train, y_train, X_test, y_test, cv)\n",
    "    fair_metrics = fair_metrics.append(\n",
    "        {\n",
    "            \"model\": \"SVM\",\n",
    "            \"group\": group,\n",
    "            \"subgroup\": subgroup,\n",
    "            \"Accuracy\": a,\n",
    "            \"Precision\": p,\n",
    "            \"Recall\": r,\n",
    "            \"AUC\": roc_auc,\n",
    "            \"FPR\": fpr,\n",
    "        },\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "fair_metrics.to_excel(\"metrics/svm_metrics.xlsx\")\n",
    "fair_metrics.to_pickle(\"metrics/svm_metrics.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dn_metrics(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    function to predict y in nn model\n",
    "    return all metrics neccessary for fairness evaluation\n",
    "    \"\"\"\n",
    "    X_test = np.asarray(X_test).astype(\"float32\")\n",
    "    yhat_probs = model.predict(X_test, verbose=0)\n",
    "    yhat_classes = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "    # reduce to 1d array\n",
    "    yhat_probs = yhat_probs[:, 0]\n",
    "    yhat_classes = yhat_classes[:, 0]\n",
    "    a = accuracy_score(y_test, yhat_classes)\n",
    "    p = precision_score(y_test, yhat_classes)\n",
    "    r = recall_score(y_test, yhat_classes)\n",
    "    roc_auc = roc_auc_score(y_test, yhat_probs)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, yhat_classes).ravel()\n",
    "    fpr = fp / (fp + tn)\n",
    "\n",
    "    return a, p, r, roc_auc, fpr\n",
    "\n",
    "\n",
    "# load model\n",
    "nn_model = load_model(\"../01_solution_probability_model/04_nn/nn/\")\n",
    "\n",
    "# predict for each subgroup\n",
    "for group, subgroup, matrice in zip(group, subgroup, matrice):\n",
    "    path = matrice + \".pkl\"\n",
    "    infile = open(path, \"rb\")\n",
    "    df = pickle.load(infile)\n",
    "    infile.close()\n",
    "\n",
    "    dataset = df[df.columns[df.columns.isin(feature_cols)]]\n",
    "    y = dataset[\"Erfolg\"]\n",
    "    X = dataset.drop(columns=[\"Erfolg\"])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=1\n",
    "    )\n",
    "    a, p, r, roc_auc, fpr = get_dn_metrics(nn_model, X_test, y_test)\n",
    "    fair_metrics = fair_metrics.append(\n",
    "        {\n",
    "            \"model\": \"NN\",\n",
    "            \"group\": group,\n",
    "            \"subgroup\": subgroup,\n",
    "            \"Accuracy\": a,\n",
    "            \"Precision\": p,\n",
    "            \"Recall\": r,\n",
    "            \"AUC\": roc_auc,\n",
    "            \"FPR\": fpr,\n",
    "        },\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "fair_metrics.to_excel(\"metrics/nn_metrics.xlsx\")\n",
    "fair_metrics.to_pickle(\"metrics/nn_metrics.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
